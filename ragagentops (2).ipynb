{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d06766d360b4c7d915203cd75ebc8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f38bbe36425241089ae2455d2e401348",
              "IPY_MODEL_341a9817e3a44e93b6d93c9894a395fb",
              "IPY_MODEL_06a6e190330b4d9db28e819e4def5334",
              "IPY_MODEL_c9f0c748618d4fbc922b6cf6789b16b3",
              "IPY_MODEL_4f87c69a13ae442da96123a60eff4da5",
              "IPY_MODEL_fa5a7299595e4164af6587c09db0470e",
              "IPY_MODEL_344e25a0044d49d6bf43e32389a325bf"
            ],
            "layout": "IPY_MODEL_7e5b38465e354d2cb7dcf07acbbf9221"
          }
        },
        "f38bbe36425241089ae2455d2e401348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca086822df947e6ac6643d4ef0265a8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b27574c239934a65be97cc074e1e5dc0",
            "value": "üìÑ Upload PDF:"
          }
        },
        "341a9817e3a44e93b6d93c9894a395fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".pdf",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_9221c17a80c64f398c95f046a322bbb5",
            "metadata": [
              {
                "name": "trial_updating.pdf",
                "type": "application/pdf",
                "size": 52357,
                "lastModified": 1751992814955
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_36d1dc9f46c74d7583dc85c2999d84ec"
          }
        },
        "06a6e190330b4d9db28e819e4def5334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Ingest PDF",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3189df14a17d47e6ab98113847db3c82",
            "style": "IPY_MODEL_7280869a85f14b3281dc4255008df9da",
            "tooltip": ""
          }
        },
        "c9f0c748618d4fbc922b6cf6789b16b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86dbf0f9d98d418d8f7483946c2d0b41",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5fe35a89fae34d50a62dcb94ea8b20bd",
            "value": "üîç Query:"
          }
        },
        "4f87c69a13ae442da96123a60eff4da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Query:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3f77062b4f784443a1d1ffc0596f452d",
            "placeholder": "Enter your query here",
            "style": "IPY_MODEL_14bfbd5eccf44165a0c48fa74dcb29f3",
            "value": "what is this about"
          }
        },
        "fa5a7299595e4164af6587c09db0470e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "Query",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4299c86e479042e9a6183438d850dc66",
            "style": "IPY_MODEL_3a26a455e4d546cfb5d160719068a2c2",
            "tooltip": ""
          }
        },
        "344e25a0044d49d6bf43e32389a325bf": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_53846ed530e2400dbe77d5b1a846de01",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "üîç Query: what is this about\n",
                  "\n",
                  "üîé Document ID: chunk-2 | Score: 0.1980\n",
                  "üìÑ Content:\n",
                  " Kit.\n",
                  "Recognized for turning research into structured, production-ready AI systems.\n",
                  "Education\n",
                  "Guru Nanak Institute Of Technology,\n",
                  "Bachelor Of Technology in computer science Engineering In Artificial Intelligence\n",
                  "and Machine Learning\n",
                  "Nov 2021 ‚Äì May 2025\n",
                  "‚Ä¢ GPA: 8.2/10.0\n",
                  "‚Ä¢ Coursework: Mathematics for ML and AI, Machine Learning, Deep Learning, Natural Language Processing,\n",
                  "Computer Vision, Hands-on with AI libraries\n",
                  "Kendriya Vidyalaya Air Force Station,\n",
                  "Higher Secondary\n",
                  "June 2018 - May 2020\n",
                  "‚Ä¢ Percen\n",
                  "\n",
                  "üîé Document ID: chunk-3 | Score: 0.1880\n",
                  "üìÑ Content:\n",
                  "tage : 75\n",
                  "‚Ä¢ Coursework: Physics, Mathematics, Computer Science(Python), Chemistry\n",
                  "Experience\n",
                  "AI Researcher and Engineer, MadScientist - T-Hub ‚Äì Hyderabad\n",
                  "May 2024 - Present\n",
                  "‚Ä¢ Conducted advanced applied research on Fake News Detection, Recommendation Systems, and Large Language\n",
                  "Models (LLMs), utilizing frameworks such as Hugging Face Transformers, PyTorch, TensorFlow, and\n",
                  "LangChain. Evaluated LLMs including GPT, Llama, Gemma, Qwen, and Mistral with detailed analysis of\n",
                  "tokenization, context windo\n",
                  "\n",
                  "üîé Document ID: chunk-100 | Score: 0.1770\n",
                  "üìÑ Content:\n",
                  "[Chunk not found]\n",
                  "\n"
                ]
              }
            ]
          }
        },
        "7e5b38465e354d2cb7dcf07acbbf9221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca086822df947e6ac6643d4ef0265a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b27574c239934a65be97cc074e1e5dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9221c17a80c64f398c95f046a322bbb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d1dc9f46c74d7583dc85c2999d84ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3189df14a17d47e6ab98113847db3c82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7280869a85f14b3281dc4255008df9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "86dbf0f9d98d418d8f7483946c2d0b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fe35a89fae34d50a62dcb94ea8b20bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f77062b4f784443a1d1ffc0596f452d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14bfbd5eccf44165a0c48fa74dcb29f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4299c86e479042e9a6183438d850dc66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a26a455e4d546cfb5d160719068a2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "53846ed530e2400dbe77d5b1a846de01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!find /content -type d -name \"__pycache__\" -exec rm -rf {} +\n"
      ],
      "metadata": {
        "id": "kSJnSeXrbPrR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers pinecone"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0oZw-QQ5bd2u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dirs = [\n",
        "    \"ragagentops\",\n",
        "    \"ragagentops/app\",\n",
        "    \"ragagentops/app/services\"\n",
        "]\n",
        "\n",
        "for d in dirs:\n",
        "    os.makedirs(d, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "s7y3PUOxbn0X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ragagentops/app/services/embedding_agent.py\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class EmbeddingAgent:\n",
        "    def __init__(self):\n",
        "        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "        print(\"‚úÖ Embedding model loaded.\")\n",
        "\n",
        "    def embed_text(self, text):\n",
        "        embedding = self.model.encode(text).tolist()\n",
        "        return embedding\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVMz7zb0bs61",
        "outputId": "7cf2ae3f-c648-4219-ea44-6c910a6f2eb2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ragagentops/app/services/embedding_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -type d -name \"__pycache__\" -exec rm -rf {} +"
      ],
      "metadata": {
        "id": "YmX8Ix9KfN1r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ragagentops/app/services/vector_store.py\n",
        "from pinecone import Pinecone\n",
        "\n",
        "class VectorStore:\n",
        "    def __init__(self, api_key, index_name):\n",
        "        self.api_key = api_key\n",
        "        self.index_name = index_name\n",
        "        self.pc = None\n",
        "        self.index = None\n",
        "\n",
        "    def connect(self):\n",
        "        \"\"\"Connect to Pinecone and initialize index.\"\"\"\n",
        "        self.pc = Pinecone(api_key=self.api_key)\n",
        "        self.index = self.pc.Index(self.index_name)\n",
        "        print(f\"‚úÖ Connected to Pinecone index: {self.index_name}\")\n",
        "\n",
        "    def upsert_vectors(self, vectors, ids):\n",
        "        \"\"\"Upsert vectors into Pinecone index.\"\"\"\n",
        "        vectors_list = vectors.tolist() if hasattr(vectors, \"tolist\") else vectors\n",
        "        records = list(zip(ids, vectors_list))\n",
        "        self.index.upsert(vectors=records)\n",
        "        print(f\"‚úÖ Upserted {len(records)} vectors.\")\n",
        "\n",
        "    def query_vector(self, vector, top_k=3):\n",
        "        \"\"\"Query Pinecone index with a vector.\"\"\"\n",
        "        vector_list = vector.tolist() if hasattr(vector, \"tolist\") else vector\n",
        "        result = self.index.query(vector=vector_list, top_k=top_k)\n",
        "        return result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7u6M6epg6SP",
        "outputId": "aabb74de-44f5-4569-d3b3-4d7e75c2c17d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ragagentops/app/services/vector_store.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"ragagentops\")\n",
        "\n",
        "from app.services.embedding_agent import EmbeddingAgent\n",
        "from app.services.vector_store import VectorStore\n",
        "from google.colab import userdata\n",
        "\n",
        "pinecone_key=userdata.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "embedding_agent = EmbeddingAgent()\n",
        "vector_store = VectorStore(api_key=pinecone_key, index_name=\"ragagentops\")\n",
        "vector_store.connect()\n",
        "\n",
        "doc_id = \"doc1\"\n",
        "content = \"This is a test document for Pinecone integration.\"\n",
        "\n",
        "embedding = embedding_agent.embed_text(content)\n",
        "vector_store.upsert_vectors([embedding], [doc_id])\n",
        "\n",
        "query = \"test document integration\"\n",
        "query_embedding = embedding_agent.embed_text(query)\n",
        "result = vector_store.query_vector(query_embedding, top_k=1)\n",
        "\n",
        "print(\"‚úÖ Query Result:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR8XiaRkc_x1",
        "outputId": "698a70ee-0b50-4612-cd04-15610c519110"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Embedding model loaded.\n",
            "‚úÖ Connected to Pinecone index: ragagentops\n",
            "‚úÖ Upserted 1 vectors.\n",
            "‚úÖ Query Result: {'matches': [{'id': 'doc1', 'score': 0.428396761, 'values': []}],\n",
            " 'namespace': '',\n",
            " 'usage': {'read_units': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3tDjnErgF7I",
        "outputId": "e215db36-16e2-41f6-e077-50e6acac5856"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLwB1DvVnHAW",
        "outputId": "818309ff-5ddb-4594-eba3-fd8918766445"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pypdf import PdfReader\n",
        "\n",
        "def download_pdf(url, save_path=\"downloaded.pdf\"):\n",
        "    \"\"\"Download a PDF from a URL.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"‚úÖ PDF downloaded and saved as {save_path}\")\n",
        "    else:\n",
        "        raise Exception(f\"Failed to download PDF. Status code: {response.status_code}\")\n",
        "\n",
        "def load_pdf_text(file_path):\n",
        "    \"\"\"Extract text from a local PDF file.\"\"\"\n",
        "    reader = PdfReader(file_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            text += page_text\n",
        "    print(f\"‚úÖ Extracted text from PDF ({len(text)} characters)\")\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "MRzp8xcfhnCd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF URL (example)\n",
        "pdf_url = \"https://arxiv.org/pdf/2106.04554.pdf\"  # You can replace this with your PDF link\n",
        "\n",
        "# Step 1: Download\n",
        "download_pdf(pdf_url, \"my_paper.pdf\")\n",
        "\n",
        "# Step 2: Extract Text\n",
        "pdf_text = load_pdf_text(\"my_paper.pdf\")\n",
        "\n",
        "# Preview extracted text\n",
        "print(pdf_text[:500])  # First 500 chars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf2dY3w1hqEr",
        "outputId": "6c7b7085-a6c6-46c4-f41b-9b968a7c556b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ PDF downloaded and saved as my_paper.pdf\n",
            "‚úÖ Extracted text from PDF (141239 characters)\n",
            "A Survey of Transformers\n",
            "TIANYANG LIN, YUXIN WANG, XIANGYANG LIU, and XIPENG QIU‚àó, School of Computer\n",
            "Science, Fudan University, China and Shanghai Key Laboratory of Intelligent Information Processing, Fudan\n",
            "University, China\n",
            "Transformers have achieved great success in many artificial intelligence fields, such as natural language\n",
            "processing, computer vision, and audio processing. Therefore, it is natural to attract lots of interest from\n",
            "academic and industry researchers. Up to the present, a gre\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest PDF text into pipeline\n",
        "embedding = embedding_agent.embed_text(pdf_text)\n",
        "vector_store.upsert_vectors([embedding], [\"my-pdf-doc\"])\n",
        "\n",
        "# Query\n",
        "query = \"what is this about ?\"\n",
        "query_embedding = embedding_agent.embed_text(query)\n",
        "result = vector_store.query_vector(vector=query_embedding, top_k=1)\n",
        "print(\"Query Result:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIqDWlu8htgp",
        "outputId": "7079de99-dd92-421e-facc-a546bffc3156"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Upserted 1 vectors.\n",
            "Query Result: {'matches': [{'id': 'chunk-24', 'score': 0.16680631, 'values': []}],\n",
            " 'namespace': '',\n",
            " 'usage': {'read_units': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pypdf import PdfReader\n",
        "from textwrap import wrap\n",
        "from google.colab import userdata\n",
        "\n",
        "pinecone_key=userdata.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "\n",
        "# ‚úÖ Initialize embedding model\n",
        "embedding_agent = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "print(\"‚úÖ Embedding model loaded.\")\n",
        "\n",
        "# ‚úÖ Connect Pinecone\n",
        "pc = Pinecone(api_key=pinecone_key)\n",
        "index = pc.Index(\"ragagentops\")\n",
        "print(\"‚úÖ Connected to Pinecone index.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8iAo9h0h03I",
        "outputId": "6d77c72f-7165-4e87-97e3-67a7b799347e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Embedding model loaded.\n",
            "‚úÖ Connected to Pinecone index.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Load PDF\n",
        "pdf_path = \"/content/my_paper.pdf\"  # Change this path to your uploaded PDF\n",
        "reader = PdfReader(pdf_path)\n",
        "pdf_text = \" \".join(page.extract_text() for page in reader.pages)\n",
        "print(\"‚úÖ PDF Loaded.\")\n",
        "\n",
        "# ‚úÖ Chunk PDF into ~1000 character chunks\n",
        "chunks = wrap(pdf_text, width=1000)\n",
        "print(f\"‚úÖ Split PDF into {len(chunks)} chunks.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-wKldLEicdF",
        "outputId": "3a78a7d8-a77d-4b59-fd62-7911ead435a3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ PDF Loaded.\n",
            "‚úÖ Split PDF into 142 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Embed & Upsert Chunks\n",
        "for idx, chunk in enumerate(chunks):\n",
        "    embedding = embedding_agent.encode(chunk).tolist()\n",
        "    index.upsert(vectors=[(f\"chunk-{idx}\", embedding)])\n",
        "\n",
        "print(\"‚úÖ All chunks upserted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDvOxp6Oimgc",
        "outputId": "3e6b50e3-d548-4149-be9c-a1cf914a66b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All chunks upserted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Query Example\n",
        "query = \"Explain the main topic discussed.\"\n",
        "query_embedding = embedding_agent.encode(query).tolist()\n",
        "\n",
        "# ‚úÖ Search Top 3 Relevant Chunks\n",
        "result = index.query(vector=query_embedding, top_k=3)\n",
        "\n",
        "print(\"Query Result:\")\n",
        "for match in result['matches']:\n",
        "    chunk_id = match['id']\n",
        "    score = match['score']\n",
        "    chunk_num = int(chunk_id.split('-')[1])\n",
        "    chunk_text = chunks[chunk_num]\n",
        "    print(f\"\\nüîé Chunk ID: {chunk_id} | Score: {score:.4f}\")\n",
        "    print(f\"üìÑ Content:\\n{chunk_text[:300]}...\")  # Showing first 300 chars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTiYG5vQivPu",
        "outputId": "2b987cc3-237d-437c-ee38-1bf974dbebdd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Result:\n",
            "\n",
            "üîé Chunk ID: chunk-25 | Score: 0.2038\n",
            "üìÑ Content:\n",
            "corresponding memory block. Fig. 4(e) depicts a commonly used case where the memory blocks are identical to their corresponding query blocks. 4.1.1.2 Compound Sparse Attention. Existing sparse attentions are often composed of more than one of the above atomic patterns. Fig. 5 illustrates some repres...\n",
            "\n",
            "üîé Chunk ID: chunk-133 | Score: 0.1784\n",
            "üìÑ Content:\n",
            "ICML. 9438‚Äì9447. http://proceedings.mlr.press/v119/tay20a.html [133] Yao-Hung Hubert Tsai, Shaojie Bai, Makoto Yamada, Louis-Philippe Morency, and Ruslan Salakhutdinov. 2019. Transformer Dissection: An Unified Understanding for Transformer‚Äôs Attention via the Lens of Kernel. InProceedings of EMNLP-I...\n",
            "\n",
            "üîé Chunk ID: chunk-26 | Score: 0.1764\n",
            "üìÑ Content:\n",
            "internal global-node attention. The global nodes are chosen to be [CLS] token for classification and all question tokens 10 Lin et al. for Question Answering tasks. They also replace some of the band attention heads in upper layers with dilated window attention to increase the receptive field withou...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Retrieve Full Text of Top Chunks\n",
        "top_matches = result['matches']\n",
        "\n",
        "for match in top_matches:\n",
        "    chunk_id = match['id']\n",
        "    score = match['score']\n",
        "    chunk_index = int(chunk_id.split('-')[1])  # Assuming IDs like \"chunk-25\"\n",
        "    chunk_text = chunks[chunk_index]\n",
        "\n",
        "    print(f\"\\nüîé Chunk ID: {chunk_id} | Score: {score:.4f}\")\n",
        "    print(f\"üìÑ Content:\\n{chunk_text}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uYYbCCBi33a",
        "outputId": "0ed7fae1-28bd-408d-8412-c94cc6b2c111"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé Chunk ID: chunk-25 | Score: 0.2038\n",
            "üìÑ Content:\n",
            "corresponding memory block. Fig. 4(e) depicts a commonly used case where the memory blocks are identical to their corresponding query blocks. 4.1.1.2 Compound Sparse Attention. Existing sparse attentions are often composed of more than one of the above atomic patterns. Fig. 5 illustrates some representative compound sparse attention patterns. k 9 q 8 (a) Star-Transformer k 9 q 8 (b) Longformer k 9 q 8 (c) ETC k 9 q 8 (d) BigBird Fig. 5. Some representative compound sparse attention patterns. The red boxes indicate sequence boundaries. Star-Transformer [43] uses a combination of band attention and global attention. Specifically, Star-Transformer just includes only a global node and a band attention with the width of 3, in which any pair of non-adjacent nodes are connected through a shared global node and adjacent nodes are connected directly with each other. This kind of sparse pattern forms a star-shaped graph among nodes. Longformer [ 10] uses a combination of band attention and\n",
            "\n",
            "\n",
            "üîé Chunk ID: chunk-133 | Score: 0.1784\n",
            "üìÑ Content:\n",
            "ICML. 9438‚Äì9447. http://proceedings.mlr.press/v119/tay20a.html [133] Yao-Hung Hubert Tsai, Shaojie Bai, Makoto Yamada, Louis-Philippe Morency, and Ruslan Salakhutdinov. 2019. Transformer Dissection: An Unified Understanding for Transformer‚Äôs Attention via the Lens of Kernel. InProceedings of EMNLP-IJCNLP . Hong Kong, China, 4344‚Äì4353. https://doi.org/10.18653/v1/D19-1443 [134] A√§ron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew W. Senior, and Koray Kavukcuoglu. 2016. WaveNet: A Generative Model for Raw Audio. InProceedings of ISCA. 125. http://www.isca-speech.org/archive/SSW_2016/abstracts/ssw9_DS-4_van_den_Oord.html [135] A√§ron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation Learning with Contrastive Predictive Coding. CoRR abs/1807.03748 (2018). arXiv:1807.03748 [136] Ashish Vaswani, Samy Bengio, Eugene Brevdo, Francois Chollet, Aidan Gomez, Stephan Gouws, Llion Jones, ≈Åukasz Kaiser, Nal Kalchbrenner,\n",
            "\n",
            "\n",
            "üîé Chunk ID: chunk-26 | Score: 0.1764\n",
            "üìÑ Content:\n",
            "internal global-node attention. The global nodes are chosen to be [CLS] token for classification and all question tokens 10 Lin et al. for Question Answering tasks. They also replace some of the band attention heads in upper layers with dilated window attention to increase the receptive field without increasing computation. As a concurrent work to Longformer [ 10], Extended Transformer Construction (ETC) [ 1] utilizes combination of band attention and external global-node attention. ETC also includes a masking mechanism to handle structured inputs and adapt Contrastive Predictive Coding (CPC) [135] for pre-training. In addition to the band and global attention, BigBird [163] uses additional random attention to approximate full attention. Their theoretical analysis also reveals that the usage of a sparse encoder and sparse decoder can simulate any Turing Machine, which explains the success of those sparse attention models. Sparse Transformer [17] uses a factorized attention where\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# ‚úÖ Load Summarizer (this will download model first time)\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "# ‚úÖ Summarize First Match\n",
        "summary = summarizer(chunk_text, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
        "print(\"\\nüìù Summary:\\n\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK5TDWlYjbLa",
        "outputId": "c9f8f49e-3996-4fa9-f88e-00bb079763f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù Summary:\n",
            "  Extended Transformer Construction (ETC) utilizes combination of band attention and external global-node attention . ETC also includes a masking mechanism to handle structured inputs and adapt Contrastive Predictive Coding (CPC) for pre-training . BigBird uses additional random attention to approximate full attention .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# ‚úÖ Load QA model (small but effective for demos)\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# ‚úÖ Use First Top Chunk for QA\n",
        "context = chunk_text  # or join multiple chunks\n",
        "\n",
        "question = \"What is this section about?\"\n",
        "answer = qa_pipeline(question=question, context=context)\n",
        "print(f\"\\nüí¨ Answer: {answer['answer']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2x8tqD6jeXd",
        "outputId": "f7a7c449-5f7c-4abc-ea4e-855c23b1e17c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üí¨ Answer: Extended Transformer Construction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**picture-perfect till here ‚úÖ**  Any doubts run the cells in sequence"
      ],
      "metadata": {
        "id": "1Z_pK1mhnK92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Ingest Document (PDF or Text)\n",
        "from google.colab import files\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# ‚úÖ Upload PDF file manually here if needed\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ‚úÖ Read uploaded PDF or Enter text manually\n",
        "pdf_file = list(uploaded.keys())[0] if uploaded else None\n",
        "if pdf_file:\n",
        "    with fitz.open(pdf_file) as doc:\n",
        "        pdf_text = \"\"\n",
        "        for page in doc:\n",
        "            pdf_text += page.get_text()\n",
        "    content = pdf_text\n",
        "    print(\"‚úÖ PDF content extracted.\")\n",
        "else:\n",
        "    content = input(\"Enter text content manually: \")\n",
        "\n",
        "# ‚úÖ Initialize agent\n",
        "embedding_agent = EmbeddingAgent()\n",
        "\n",
        "doc_id = input(\"Enter Document ID: \")\n",
        "embedding = embedding_agent.embed_text(content)  # ‚úÖ CORRECT\n",
        "vector_store.upsert_vectors([embedding], [doc_id])\n",
        "print(f\"‚úÖ Document '{doc_id}' ingested successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "veUFuXCNxtHS",
        "outputId": "04eddbf8-fd3e-4454-b8e9-789445fd37df"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3ed40b9a-4bea-497e-9867-61e2fce4ef55\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3ed40b9a-4bea-497e-9867-61e2fce4ef55\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving trial_updating.pdf to trial_updating (1).pdf\n",
            "‚úÖ PDF content extracted.\n",
            "‚úÖ Embedding model loaded.\n",
            "Enter Document ID: trial_updating_69\n",
            "‚úÖ Upserted 1 vectors.\n",
            "‚úÖ Document 'trial_updating_69' ingested successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Query the document\n",
        "query = input(\"Enter your query: \")\n",
        "query_embedding = embedding_agent.embed_text(query)\n",
        "result = vector_store.query_vector(vector=query_embedding, top_k=3)\n",
        "\n",
        "# ‚úÖ Display results\n",
        "print(\"üîé Query Result:\\n\")\n",
        "for match in result['matches']:\n",
        "    doc_id = match['id']\n",
        "    score = match['score']\n",
        "    print(f\"üìÑ Document ID: {doc_id}\")\n",
        "    print(f\"üî¢ Score: {score}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br0oaAboyJJZ",
        "outputId": "fad75098-9da0-4bbb-fa72-cf2169f27a43"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query: what is this about ?\n",
            "üîé Query Result:\n",
            "\n",
            "üìÑ Document ID: chunk-24\n",
            "üî¢ Score: 0.16680631\n",
            "\n",
            "üìÑ Document ID: chunk-20\n",
            "üî¢ Score: 0.166210338\n",
            "\n",
            "üìÑ Document ID: chunk-100\n",
            "üî¢ Score: 0.164624885\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Successfully done**"
      ],
      "metadata": {
        "id": "uCXX7n861Jop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Install packages (only once)\n",
        "!pip install ipywidgets PyMuPDF --quiet\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# ‚úÖ Widgets\n",
        "upload_widget = widgets.FileUpload(accept='.pdf', multiple=False)\n",
        "query_widget = widgets.Text(description=\"Query:\", placeholder='Enter your query here')\n",
        "ingest_button = widgets.Button(description=\"Ingest PDF\", button_style='success')\n",
        "query_button = widgets.Button(description=\"Query\", button_style='info')\n",
        "output = widgets.Output()\n",
        "\n",
        "# ‚úÖ Helper functions\n",
        "chunks_dict = {}  # Stores chunk_id ‚Üí text mapping\n",
        "\n",
        "def extract_pdf_chunks(file_bytes, chunk_size=500):\n",
        "    with fitz.open(stream=file_bytes, filetype=\"pdf\") as doc:\n",
        "        full_text = \"\"\n",
        "        for page in doc:\n",
        "            full_text += page.get_text()\n",
        "    chunks = [full_text[i:i + chunk_size] for i in range(0, len(full_text), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "def on_ingest_clicked(b):\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        if not upload_widget.value:\n",
        "            print(\"‚ö†Ô∏è Please upload a PDF.\")\n",
        "            return\n",
        "        uploaded_file = list(upload_widget.value.values())[0]\n",
        "        chunks = extract_pdf_chunks(uploaded_file['content'])\n",
        "        print(f\"‚úÖ PDF extracted into {len(chunks)} chunks.\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            embedding = embedding_agent.embed_text(chunk)\n",
        "            chunk_id = f\"chunk-{i}\"\n",
        "            vector_store.upsert_vectors([embedding], [chunk_id])\n",
        "            chunks_dict[chunk_id] = chunk\n",
        "        print(f\"‚úÖ {len(chunks)} chunks ingested successfully.\")\n",
        "\n",
        "def on_query_clicked(b):\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        query = query_widget.value\n",
        "        query_embedding = embedding_agent.embed_text(query)\n",
        "        result = vector_store.query_vector(vector=query_embedding, top_k=3)\n",
        "        print(f\"üîç Query: {query}\\n\")\n",
        "        for match in result['matches']:\n",
        "            chunk_id = match['id']\n",
        "            score = match['score']\n",
        "            chunk_text = chunks_dict.get(chunk_id, \"[Chunk not found]\")\n",
        "            print(f\"üîé Document ID: {chunk_id} | Score: {score:.4f}\\nüìÑ Content:\\n{chunk_text}\\n\")\n",
        "\n",
        "# ‚úÖ Bind events\n",
        "ingest_button.on_click(on_ingest_clicked)\n",
        "query_button.on_click(on_query_clicked)\n",
        "\n",
        "# ‚úÖ Show UI\n",
        "display(\n",
        "    widgets.VBox([\n",
        "        widgets.Label(\"üìÑ Upload PDF:\"),\n",
        "        upload_widget,\n",
        "        ingest_button,\n",
        "        widgets.Label(\"üîç Query:\"),\n",
        "        query_widget,\n",
        "        query_button,\n",
        "        output\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886,
          "referenced_widgets": [
            "4d06766d360b4c7d915203cd75ebc8e3",
            "f38bbe36425241089ae2455d2e401348",
            "341a9817e3a44e93b6d93c9894a395fb",
            "06a6e190330b4d9db28e819e4def5334",
            "c9f0c748618d4fbc922b6cf6789b16b3",
            "4f87c69a13ae442da96123a60eff4da5",
            "fa5a7299595e4164af6587c09db0470e",
            "344e25a0044d49d6bf43e32389a325bf",
            "7e5b38465e354d2cb7dcf07acbbf9221",
            "0ca086822df947e6ac6643d4ef0265a8",
            "b27574c239934a65be97cc074e1e5dc0",
            "9221c17a80c64f398c95f046a322bbb5",
            "36d1dc9f46c74d7583dc85c2999d84ec",
            "3189df14a17d47e6ab98113847db3c82",
            "7280869a85f14b3281dc4255008df9da",
            "86dbf0f9d98d418d8f7483946c2d0b41",
            "5fe35a89fae34d50a62dcb94ea8b20bd",
            "3f77062b4f784443a1d1ffc0596f452d",
            "14bfbd5eccf44165a0c48fa74dcb29f3",
            "4299c86e479042e9a6183438d850dc66",
            "3a26a455e4d546cfb5d160719068a2c2",
            "53846ed530e2400dbe77d5b1a846de01"
          ]
        },
        "id": "KACzTj6D1ApD",
        "outputId": "b6b098e9-7c1c-4d65-c99e-3abc2238398b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='üìÑ Upload PDF:'), FileUpload(value={}, accept='.pdf', description='Upload'), Button‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d06766d360b4c7d915203cd75ebc8e3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perfectly Working**"
      ],
      "metadata": {
        "id": "qSYsgVBD3TRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IHuixiZ1ipu",
        "outputId": "f50ce103-48eb-4ec8-8007-2e04b385daa7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"21831a6631@gniindia.org\"\n",
        "!git config --global user.name \"ks-suraj\"\n"
      ],
      "metadata": {
        "id": "gNUrEK0p1xws"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ks-suraj/projects.git\n",
        "%cd projects\n",
        "!git checkout RAG-Agent-Ops\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzGpka503w-d",
        "outputId": "e8c865c2-0cb0-4d0f-e7ab-f4e8c73cf555"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'projects'...\n",
            "remote: Enumerating objects: 427, done.\u001b[K\n",
            "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (167/167), done.\u001b[K\n",
            "remote: Total 427 (delta 97), reused 236 (delta 59), pack-reused 147 (from 1)\u001b[K\n",
            "Receiving objects: 100% (427/427), 389.17 KiB | 3.54 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n",
            "/content/projects\n",
            "Branch 'RAG-Agent-Ops' set up to track remote branch 'RAG-Agent-Ops' from 'origin'.\n",
            "Switched to a new branch 'RAG-Agent-Ops'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/ragagentops ./ragagentops\n"
      ],
      "metadata": {
        "id": "X4oH4eYE4MYn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ragagentops\n",
        "!git commit -m \"Add RAG-Agent-Ops pipeline from Colab\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Od5g7xC4PDE",
        "outputId": "99841ffb-97b1-4e8b-d602-c5fad36bd1e1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RAG-Agent-Ops 943fa1a] Add RAG-Agent-Ops pipeline from Colab\n",
            " 4 files changed, 37 insertions(+)\n",
            " create mode 100644 ragagentops/app/services/__pycache__/embedding_agent.cpython-311.pyc\n",
            " create mode 100644 ragagentops/app/services/__pycache__/vector_store.cpython-311.pyc\n",
            " create mode 100644 ragagentops/app/services/embedding_agent.py\n",
            " create mode 100644 ragagentops/app/services/vector_store.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "token = userdata.get('GITHUB_TOKEN')  # assuming you saved it in Colab secrets\n"
      ],
      "metadata": {
        "id": "GYaN1xHD4kRH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = userdata.get(\"GITHUB_TOKEN\")\n",
        "repo_url = f\"https://{token}@github.com/ks-suraj/projects.git\"\n",
        "\n",
        "# Now pass it using shell command\n",
        "!git remote set-url origin \"{repo_url}\"\n",
        "!git push origin RAG-Agent-Ops\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty0UzUFj4REB",
        "outputId": "6a653706-064e-4b85-e1f0-ea3c0c6cfa4b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 11, done.\n",
            "Counting objects:   9% (1/11)\rCounting objects:  18% (2/11)\rCounting objects:  27% (3/11)\rCounting objects:  36% (4/11)\rCounting objects:  45% (5/11)\rCounting objects:  54% (6/11)\rCounting objects:  63% (7/11)\rCounting objects:  72% (8/11)\rCounting objects:  81% (9/11)\rCounting objects:  90% (10/11)\rCounting objects: 100% (11/11)\rCounting objects: 100% (11/11), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  12% (1/8)\rCompressing objects:  25% (2/8)\rCompressing objects:  37% (3/8)\rCompressing objects:  50% (4/8)\rCompressing objects:  62% (5/8)\rCompressing objects:  75% (6/8)\rCompressing objects:  87% (7/8)\rCompressing objects: 100% (8/8)\rCompressing objects: 100% (8/8), done.\n",
            "Writing objects:  10% (1/10)\rWriting objects:  20% (2/10)\rWriting objects:  30% (3/10)\rWriting objects:  40% (4/10)\rWriting objects:  50% (5/10)\rWriting objects:  60% (6/10)\rWriting objects:  70% (7/10)\rWriting objects:  80% (8/10)\rWriting objects:  90% (9/10)\rWriting objects: 100% (10/10)\rWriting objects: 100% (10/10), 2.96 KiB | 2.96 MiB/s, done.\n",
            "Total 10 (delta 0), reused 0 (delta 0), pack-reused 0\n",
            "To https://github.com/ks-suraj/projects.git\n",
            "   38738b2..943fa1a  RAG-Agent-Ops -> RAG-Agent-Ops\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Everything is Done and Pushed**"
      ],
      "metadata": {
        "id": "nWS7eJia6I1K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "faQ6xYvp8Jby"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}